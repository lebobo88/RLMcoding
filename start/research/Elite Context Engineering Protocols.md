Elite Context Engineering Protocols

1. Core Directive: R&D Framework
Your primary objective is to manage the context window resource efficiency using the R&D methodology:

Reduce: Minimize the amount of context loaded into the primary agent.

Delegate: Offload tasks and context to sub-agents, background processes, or other instances.

2. Level I: Basic Context Hygiene (Reduce)
Techniques to minimize token usage in the primary context window.

A. MCP Server Management
Protocol: Do not autoload Model Context Protocol (MCP) servers unless strictly necessary for the current task. Defaulting to all MCPs wastes tokens (approx. 12% overhead in examples).

Action:

Delete or disable the default mcp.json file in the codebase. [02:12]

Manual Loading: Only load MCPs explicitly when needed for a session using mcp config.

Specialized Configs: Create specialized configuration files (e.g., firecrawl_mcp_config.json) that only load specific tools (like a web scraper) for specific agents. [02:46]

B. Context Priming vs. Static Memory
Protocol: Avoid large, static memory files (e.g., project.md or claude.md) that are automatically loaded into every session. These files grow indefinitely and pollute context.

Action:

Trim Memory Files: Reduce global memory files to only the absolute universal essentials (e.g., <50 lines). [05:59]

Use Context Priming: Create reusable "Prime Commands" (custom slash commands like /prime_bug, /prime_feature) that load specific context only when that specific task type is initiated. [06:40]

Structure: A prime command should contain the Purpose, Run Step, Read Step, and Report Step relevant only to that task.

3. Level II: Intermediate Delegation (Delegate)
Techniques to offload work to sub-processes to keep the main context clean.

A. Sub-Agent Delegation
Protocol: Use sub-agents to perform high-token tasks (like web scraping or documentation fetching) without polluting the primary agent's history.

Mechanism: Sub-agents run on System Prompts, effectively creating a partially forked context window. Tokens generated by sub-agents do not count against the primary agent's limit. [09:56]

Action:

Create reusable commands (e.g., /load_ai_docs) that spawn sub-agents to read files, scrape URLs, or process data. [10:40]

The sub-agent performs the work and writes the output to a file. The primary agent only reads the final output file, saving thousands of tokens.

4. Level III: Advanced Agentic Patterns (Manage & Scale)
Techniques for persistent state and multi-agent orchestration.

A. Context Bundles
Protocol: Maintain a "trail of work" to restore agent state or debug without reloading the full verbose history.

Mechanism: Use "Hooks" to generate Context Bundlesâ€”append-only logs of critical actions (Prompts, Reads, Tool Inputs) saved with a session ID. [15:18]

Usage:

If an agent's context explodes, use /load_bundle to feed a summarized history into a fresh instance. This restores the "story" of the session without the heavy token load of every intermediate step. [17:38]

B. Primary Agent Delegation (Background Agents)
Protocol: Escape the "human-in-the-loop" bottleneck by firing full background instances for autonomous tasks.

Mechanism: Use commands like /background to spawn a completely independent operating system process (CLI or SDK based) that runs a "Quick Plan" or workflow. [20:47]

Workflow:

Primary agent issues a command.

Background agent spins up (Out-of-Loop).

Background agent executes the plan and writes to a specific report file.

Primary agent is notified upon completion.

Benefit: Allows orchestration of multiple compute agents simultaneously without occupying the user's active terminal or context window.

5. Summary Checklist for Agent Optimization
Audit Context: Run /context to check token usage. If high on startup, delete default MCPs and shrink memory files.

Specialization: Create specific agents (Experts) for specific domains rather than one generalist agent.

Out-of-Loop Scaling: Move from "Babysitting" agents to orchestrating background agents that report back via file I/O.

Golden Rule: Spend tokens to prevent errors, not to fix them. A focused context window leads to higher accuracy and fewer corrections.